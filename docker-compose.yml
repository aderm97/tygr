version: '3.8'

services:
  # TYGR Sandbox Container - Pre-built environment for security testing
  tygr-sandbox:
    build:
      context: .
      dockerfile: containers/Dockerfile
    image: tygr-sandbox:latest
    container_name: tygr-sandbox
    hostname: tygr-sandbox

    # Environment variables for TYGR configuration
    environment:
      - TYGR_LLM=${TYGR_LLM:-openai/gpt-4o}
      - LLM_API_KEY=${LLM_API_KEY}
      - LLM_API_BASE=${LLM_API_BASE:-}
      - PERPLEXITY_API_KEY=${PERPLEXITY_API_KEY:-}
      - TYGR_SANDBOX_MODE=true
      - PYTHONPATH=/app
      - REQUESTS_CA_BUNDLE=/etc/ssl/certs/ca-certificates.crt
      - SSL_CERT_FILE=/etc/ssl/certs/ca-certificates.crt

    # Mount volumes for persistent data and code
    volumes:
      # Mount the workspace for testing targets
      - ./test-workspace:/workspace
      # Mount results directory to access scan outputs
      - ./agent_runs:/workspace/agent_runs
      # Mount source code for development (optional)
      # - ./tygr:/app/tygr

    # Networking
    network_mode: bridge

    # Keep container running for interactive use
    stdin_open: true
    tty: true

    # Resource limits (adjust based on your system)
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 8G
        reservations:
          cpus: '2.0'
          memory: 4G

    # Security options for penetration testing tools
    cap_add:
      - NET_ADMIN
      - NET_RAW

    # Restart policy
    restart: unless-stopped

  # Optional: Local LLM using Ollama (uncomment to use)
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: tygr-ollama
  #   volumes:
  #     - ollama-data:/root/.ollama
  #   ports:
  #     - "11434:11434"
  #   restart: unless-stopped

volumes:
  # Persistent volume for Ollama models (if using local LLM)
  # ollama-data:

networks:
  default:
    name: tygr-network
